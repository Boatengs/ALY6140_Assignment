{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcf0ff3-9631-47c9-ac40-68f24e8ce9e1",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "In this assignment you will explore data injestion, data storage and basic DataFrame manipulation. ALso you are expected to complete a Mini Project.\n",
    "\n",
    "You have been provided with several datafiles both for your testing and they are the files that I will utilize when evaluating your assignment. \n",
    "\n",
    "Each problem asks you to write a single function. The functions are designed to build on one another, so you should utilize earlier functions as part of the solution to later functions. \n",
    "\n",
    "All functions receive all of the information that need to operate from their parameters. Other information may be generated within the function. Besides calling other functions, you should not reference any other infromation that exists outside of your  functions. Print statements can be used for debugging purposes but should not be included in your final solutions. All functions should return something as specified in the problem.\n",
    "\n",
    "Each function **MUST** be fully documented using appropriate documenting technique as described in the lecture.\n",
    "\n",
    "Include all of your datafiles in the same folder that your Jupyter Notebook resides. **Do not** add any additional path information to your filenames.\n",
    "\n",
    "You must upload all your notebook files on GITHUB and PDF File on Canvas. I will be evaluating your actual .ipynb files on GUTHUB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d177b09-0e5f-409d-bc42-54be2c27db01",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Problem **read_data**\n",
    "\n",
    "Write a function called **read_data**.\n",
    "\n",
    "This function should accept a single parameter which I will refer to as **filename**\n",
    "\n",
    "**filename** will be a complete description of a filename with a name, a dot, and a 3 letter extensions. For example the filename could be \"hockey.xlsx\" or \"hockey.xls\" which would also imply that it is an excel. file. Other extensions that you need to support include .json, .csv, .txt (all text files will use vertical bars | as a separator between data). \n",
    "\n",
    "The function will return a Pandas dataframe with the data in the file. For the purposes of this function all excel files will be single sheet with easily read in data, you can also assume that the header column of excel files will always be 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21433264-4bdd-4df6-9e90-69460f5a937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 1 Solution Here\n",
    "\n",
    "import pandas as pd  \n",
    "import os \n",
    "\n",
    "def read_data(filename):\n",
    "    cwd = os.getcwd()  \n",
    "    filepath = os.path.join(cwd, filename) \n",
    "\n",
    "    if filename.endswith('.xlsx'):  \n",
    "        data = pd.read_excel(filepath)  \n",
    "    elif filename.endswith('.json'):  \n",
    "        data = pd.read_json(filepath) \n",
    "    elif filename.endswith('.csv'):  \n",
    "        data = pd.read_csv(filepath)  \n",
    "    elif filename.endswith('.txt'):  \n",
    "        with open(filepath, 'r') as f: \n",
    "            data = pd.read_csv(f, delimiter='\\t')  \n",
    "    else: \n",
    "        raise ValueError(\"Unsupported file format\")  \n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ef4ac3e-1e68-4c18-88be-4217a3a05ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"hockeyplayers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "12c2ed4b-2d15-419a-b550-8681a4318c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_data(\"nested_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "975d5526-36de-4f5d-a934-4ad57291d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = read_data(\"network_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6276f441-3fe9-4ac1-9bb9-49b3d9790329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = read_data(\"Neural_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d8b756b-a1da-448b-8c9f-e368b5454414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Team</th>\n",
       "      <th>Country</th>\n",
       "      <th>NameF</th>\n",
       "      <th>NameL</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HeightFt</th>\n",
       "      <th>HtIn</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Meghan</td>\n",
       "      <td>Agosta</td>\n",
       "      <td>148</td>\n",
       "      <td>5'7</td>\n",
       "      <td>1987-02-12</td>\n",
       "      <td>Ruthven</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>35</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>148</td>\n",
       "      <td>5'9</td>\n",
       "      <td>1989-09-24</td>\n",
       "      <td>Sudbury</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>32</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Stacey</td>\n",
       "      <td>156</td>\n",
       "      <td>5'10</td>\n",
       "      <td>1994-05-05</td>\n",
       "      <td>Kleinburg</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>28</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>172</td>\n",
       "      <td>5'10</td>\n",
       "      <td>1989-06-15</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>33</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jillian</td>\n",
       "      <td>Saulnier</td>\n",
       "      <td>144</td>\n",
       "      <td>5'5</td>\n",
       "      <td>1992-03-07</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>N.S.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>30</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Team Country     NameF      NameL  Weight Height        DOB  \\\n",
       "0   1  Women  Canada    Meghan     Agosta     148    5'7 1987-02-12   \n",
       "1   2  Women  Canada   Rebecca   Johnston     148    5'9 1989-09-24   \n",
       "2   3  Women  Canada     Laura     Stacey     156   5'10 1994-05-05   \n",
       "3   4  Women  Canada  Jennifer  Wakefield     172   5'10 1989-06-15   \n",
       "4   5  Women  Canada   Jillian   Saulnier     144    5'5 1992-03-07   \n",
       "\n",
       "    Hometown  Prov      Pos  Age  HeightFt  HtIn  BMI  \n",
       "0    Ruthven  Ont.  Forward   35  5.583333    67   23  \n",
       "1    Sudbury  Ont.  Forward   32  5.750000    69   22  \n",
       "2  Kleinburg  Ont.  Forward   28  5.833333    70   22  \n",
       "3  Pickering  Ont.  Forward   33  5.833333    70   25  \n",
       "4    Halifax  N.S.  Forward   30  5.416667    65   24  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "85f14199-badd-4df7-b231-31473a196fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>:@computed_region_cbhk_fwbd</th>\n",
       "      <th>:@computed_region_nnqa_25f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [6.08333, 50....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [10.23333, 56...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abee</td>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1952-01-01T00:00:00.000</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-113, 54.216...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1976-01-01T00:00:00.000</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-99.9, 16.88...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achiras</td>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1902-01-01T00:00:00.000</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-64.95, -33....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   id nametype     recclass      mass  fall  \\\n",
       "0    Aachen    1    Valid           L5      21.0  Fell   \n",
       "1    Aarhus    2    Valid           H6     720.0  Fell   \n",
       "2      Abee    6    Valid          EH4  107000.0  Fell   \n",
       "3  Acapulco   10    Valid  Acapulcoite    1914.0  Fell   \n",
       "4   Achiras  370    Valid           L6     780.0  Fell   \n",
       "\n",
       "                      year    reclat    reclong  \\\n",
       "0  1880-01-01T00:00:00.000  50.77500    6.08333   \n",
       "1  1951-01-01T00:00:00.000  56.18333   10.23333   \n",
       "2  1952-01-01T00:00:00.000  54.21667 -113.00000   \n",
       "3  1976-01-01T00:00:00.000  16.88333  -99.90000   \n",
       "4  1902-01-01T00:00:00.000 -33.16667  -64.95000   \n",
       "\n",
       "                                         geolocation  \\\n",
       "0  {'type': 'Point', 'coordinates': [6.08333, 50....   \n",
       "1  {'type': 'Point', 'coordinates': [10.23333, 56...   \n",
       "2  {'type': 'Point', 'coordinates': [-113, 54.216...   \n",
       "3  {'type': 'Point', 'coordinates': [-99.9, 16.88...   \n",
       "4  {'type': 'Point', 'coordinates': [-64.95, -33....   \n",
       "\n",
       "   :@computed_region_cbhk_fwbd  :@computed_region_nnqa_25f4  \n",
       "0                          NaN                          NaN  \n",
       "1                          NaN                          NaN  \n",
       "2                          NaN                          NaN  \n",
       "3                          NaN                          NaN  \n",
       "4                          NaN                          NaN  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ba5da26-4a72-449d-9a32-7313b3e71f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_visitor</th>\n",
       "      <th>id_session</th>\n",
       "      <th>dim_session_number</th>\n",
       "      <th>dim_user_agent</th>\n",
       "      <th>dim_device_app_combo</th>\n",
       "      <th>ds</th>\n",
       "      <th>ts_min</th>\n",
       "      <th>ts_max</th>\n",
       "      <th>did_search</th>\n",
       "      <th>sent_message</th>\n",
       "      <th>...</th>\n",
       "      <th>next_id_session</th>\n",
       "      <th>next_dim_session_number</th>\n",
       "      <th>next_dim_user_agent</th>\n",
       "      <th>next_dim_device_app_combo</th>\n",
       "      <th>next_ds</th>\n",
       "      <th>next_ts_min</th>\n",
       "      <th>next_ts_max</th>\n",
       "      <th>next_did_search</th>\n",
       "      <th>next_sent_message</th>\n",
       "      <th>next_sent_booking_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed1329a6-064d-47e9-93bc-93f5a50822df</td>\n",
       "      <td>a8dfb8ed5aa79e00ff14b2da297c9778</td>\n",
       "      <td>83</td>\n",
       "      <td>Airbnb/6.0 iPhone/8.1.2</td>\n",
       "      <td>iPhone - iOS</td>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>2015-02-16 21:50:41</td>\n",
       "      <td>2015-02-16 22:13:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>b812bf56bf89b0b31f4e5b50d0c15ff8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 11:57:15</td>\n",
       "      <td>2015-02-18 12:12:48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed1329a6-064d-47e9-93bc-93f5a50822df</td>\n",
       "      <td>950277daef16f86dc2c05d2b212eea81</td>\n",
       "      <td>84</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 11:57:15</td>\n",
       "      <td>2015-02-18 12:12:48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>456083b5f5506ad125d595006819de1d</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 13:02:13</td>\n",
       "      <td>2015-02-18 13:05:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ed1329a6-064d-47e9-93bc-93f5a50822df</td>\n",
       "      <td>ee4e2f99dd0c0bef2d40e4bdf880c862</td>\n",
       "      <td>85</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 13:02:13</td>\n",
       "      <td>2015-02-18 13:05:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>94d30e9f3c8f92ae691e49d77a884777</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 14:18:17</td>\n",
       "      <td>2015-02-18 14:28:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed1329a6-064d-47e9-93bc-93f5a50822df</td>\n",
       "      <td>59fbde7b5d35403116c461fa7fc1ab6e</td>\n",
       "      <td>86</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>2015-02-18 14:18:17</td>\n",
       "      <td>2015-02-18 14:28:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>ab02139dc81bea4b126cf5043faf53d9</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>2015-02-19 12:24:57</td>\n",
       "      <td>2015-02-19 12:24:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed1329a6-064d-47e9-93bc-93f5a50822df</td>\n",
       "      <td>ec8972a3c7256ea4dcba61ee2bd9e3a8</td>\n",
       "      <td>87</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>2015-02-19 12:24:57</td>\n",
       "      <td>2015-02-19 12:24:59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6a69db1a5876e9798947f20e2c52bcc8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>\n",
       "      <td>Desktop - Chrome</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>2015-02-19 22:21:58</td>\n",
       "      <td>2015-02-19 22:22:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id_visitor                        id_session  \\\n",
       "0  ed1329a6-064d-47e9-93bc-93f5a50822df  a8dfb8ed5aa79e00ff14b2da297c9778   \n",
       "1  ed1329a6-064d-47e9-93bc-93f5a50822df  950277daef16f86dc2c05d2b212eea81   \n",
       "2  ed1329a6-064d-47e9-93bc-93f5a50822df  ee4e2f99dd0c0bef2d40e4bdf880c862   \n",
       "3  ed1329a6-064d-47e9-93bc-93f5a50822df  59fbde7b5d35403116c461fa7fc1ab6e   \n",
       "4  ed1329a6-064d-47e9-93bc-93f5a50822df  ec8972a3c7256ea4dcba61ee2bd9e3a8   \n",
       "\n",
       "   dim_session_number                                     dim_user_agent  \\\n",
       "0                  83                            Airbnb/6.0 iPhone/8.1.2   \n",
       "1                  84  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "2                  85  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "3                  86  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "4                  87  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "\n",
       "  dim_device_app_combo          ds               ts_min               ts_max  \\\n",
       "0         iPhone - iOS  2015-02-16  2015-02-16 21:50:41  2015-02-16 22:13:42   \n",
       "1     Desktop - Chrome  2015-02-18  2015-02-18 11:57:15  2015-02-18 12:12:48   \n",
       "2     Desktop - Chrome  2015-02-18  2015-02-18 13:02:13  2015-02-18 13:05:36   \n",
       "3     Desktop - Chrome  2015-02-18  2015-02-18 14:18:17  2015-02-18 14:28:47   \n",
       "4     Desktop - Chrome  2015-02-19  2015-02-19 12:24:57  2015-02-19 12:24:59   \n",
       "\n",
       "   did_search  sent_message  ...                   next_id_session  \\\n",
       "0           0             0  ...  b812bf56bf89b0b31f4e5b50d0c15ff8   \n",
       "1           0             0  ...  456083b5f5506ad125d595006819de1d   \n",
       "2           0             0  ...  94d30e9f3c8f92ae691e49d77a884777   \n",
       "3           0             0  ...  ab02139dc81bea4b126cf5043faf53d9   \n",
       "4           0             0  ...  6a69db1a5876e9798947f20e2c52bcc8   \n",
       "\n",
       "  next_dim_session_number                                next_dim_user_agent  \\\n",
       "0                    84.0  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "1                    85.0  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "2                    86.0  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "3                    87.0  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "4                    88.0  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
       "\n",
       "  next_dim_device_app_combo     next_ds          next_ts_min  \\\n",
       "0          Desktop - Chrome  2015-02-18  2015-02-18 11:57:15   \n",
       "1          Desktop - Chrome  2015-02-18  2015-02-18 13:02:13   \n",
       "2          Desktop - Chrome  2015-02-18  2015-02-18 14:18:17   \n",
       "3          Desktop - Chrome  2015-02-19  2015-02-19 12:24:57   \n",
       "4          Desktop - Chrome  2015-02-19  2015-02-19 22:21:58   \n",
       "\n",
       "           next_ts_max next_did_search  next_sent_message  \\\n",
       "0  2015-02-18 12:12:48             0.0                0.0   \n",
       "1  2015-02-18 13:05:36             0.0                0.0   \n",
       "2  2015-02-18 14:28:47             0.0                0.0   \n",
       "3  2015-02-19 12:24:59             0.0                0.0   \n",
       "4  2015-02-19 22:22:02             0.0                0.0   \n",
       "\n",
       "   next_sent_booking_request  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35867156-e33e-4920-a205-77f61b37238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intensity_MassDisplacement_PI</th>\n",
       "      <th>Intensity_MaxIntensityEdge_DAPI</th>\n",
       "      <th>Intensity_MaxIntensityEdge_PI</th>\n",
       "      <th>Intensity_MaxIntensity_DAPI</th>\n",
       "      <th>Intensity_MaxIntensity_PI</th>\n",
       "      <th>Intensity_MeanIntensityEdge_DAPI</th>\n",
       "      <th>Intensity_MeanIntensityEdge_PI</th>\n",
       "      <th>Intensity_MeanIntensity_DAPI</th>\n",
       "      <th>Intensity_MeanIntensity_PI</th>\n",
       "      <th>Intensity_MedianIntensity_DAPI</th>\n",
       "      <th>...</th>\n",
       "      <th>Intensity_MinIntensityEdge_PI</th>\n",
       "      <th>Intensity_MinIntensity_DAPI</th>\n",
       "      <th>Intensity_MinIntensity_PI</th>\n",
       "      <th>Intensity_StdIntensityEdge_DAPI</th>\n",
       "      <th>Intensity_StdIntensityEdge_PI</th>\n",
       "      <th>Intensity_StdIntensity_DAPI</th>\n",
       "      <th>Intensity_StdIntensity_PI</th>\n",
       "      <th>Intensity_UpperQuartileIntensity_DAPI</th>\n",
       "      <th>Intensity_UpperQuartileIntensity_PI</th>\n",
       "      <th>Number_Object_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071353</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.148211</td>\n",
       "      <td>0.042130</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.035751</td>\n",
       "      <td>0.085337</td>\n",
       "      <td>0.036167</td>\n",
       "      <td>0.092348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.107881</td>\n",
       "      <td>0.037224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.127836</td>\n",
       "      <td>0.054536</td>\n",
       "      <td>0.038636</td>\n",
       "      <td>0.157321</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>0.090578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028016</td>\n",
       "      <td>0.029816</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.121820</td>\n",
       "      <td>0.037316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105791</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.120699</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>0.052591</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.019099</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.092367</td>\n",
       "      <td>0.032090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144962</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.133516</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.031724</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.071058</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.072862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.026749</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.030482</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.096674</td>\n",
       "      <td>0.034585</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148326</td>\n",
       "      <td>0.055924</td>\n",
       "      <td>0.038834</td>\n",
       "      <td>0.142733</td>\n",
       "      <td>0.038834</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.033576</td>\n",
       "      <td>0.083392</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.085504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>0.031708</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.030331</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.110895</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intensity_MassDisplacement_PI  Intensity_MaxIntensityEdge_DAPI  \\\n",
       "0                       0.071353                         0.056657   \n",
       "1                       0.127836                         0.054536   \n",
       "2                       0.105791                         0.068132   \n",
       "3                       0.144962                         0.043870   \n",
       "4                       0.148326                         0.055924   \n",
       "\n",
       "   Intensity_MaxIntensityEdge_PI  Intensity_MaxIntensity_DAPI  \\\n",
       "0                       0.039338                     0.148211   \n",
       "1                       0.038636                     0.157321   \n",
       "2                       0.034424                     0.120699   \n",
       "3                       0.036103                     0.133516   \n",
       "4                       0.038834                     0.142733   \n",
       "\n",
       "   Intensity_MaxIntensity_PI  Intensity_MeanIntensityEdge_DAPI  \\\n",
       "0                   0.042130                          0.040214   \n",
       "1                   0.040787                          0.039137   \n",
       "2                   0.035325                          0.052591   \n",
       "3                   0.036927                          0.031724   \n",
       "4                   0.038834                          0.041327   \n",
       "\n",
       "   Intensity_MeanIntensityEdge_PI  Intensity_MeanIntensity_DAPI  \\\n",
       "0                        0.035751                      0.085337   \n",
       "1                        0.032968                      0.089130   \n",
       "2                        0.030549                      0.078406   \n",
       "3                        0.032415                      0.071058   \n",
       "4                        0.033576                      0.083392   \n",
       "\n",
       "   Intensity_MeanIntensity_PI  Intensity_MedianIntensity_DAPI  ...  \\\n",
       "0                    0.036167                        0.092348  ...   \n",
       "1                    0.035318                        0.090578  ...   \n",
       "2                    0.031173                        0.079522  ...   \n",
       "3                    0.033550                        0.072862  ...   \n",
       "4                    0.034231                        0.085504  ...   \n",
       "\n",
       "   Intensity_MinIntensityEdge_PI  Intensity_MinIntensity_DAPI  \\\n",
       "0                       0.031388                     0.031815   \n",
       "1                       0.028016                     0.029816   \n",
       "2                       0.027512                     0.038941   \n",
       "3                       0.028748                     0.026749   \n",
       "4                       0.028244                     0.031708   \n",
       "\n",
       "   Intensity_MinIntensity_PI  Intensity_StdIntensityEdge_DAPI  \\\n",
       "0                   0.031388                         0.005757   \n",
       "1                   0.027481                         0.005620   \n",
       "2                   0.027512                         0.007579   \n",
       "3                   0.028748                         0.003096   \n",
       "4                   0.028153                         0.005773   \n",
       "\n",
       "   Intensity_StdIntensityEdge_PI  Intensity_StdIntensity_DAPI  \\\n",
       "0                       0.001566                     0.029094   \n",
       "1                       0.002464                     0.036908   \n",
       "2                       0.001566                     0.019099   \n",
       "3                       0.001483                     0.030482   \n",
       "4                       0.002650                     0.030331   \n",
       "\n",
       "   Intensity_StdIntensity_PI  Intensity_UpperQuartileIntensity_DAPI  \\\n",
       "0                   0.001507                               0.107881   \n",
       "1                   0.002593                               0.121820   \n",
       "2                   0.001467                               0.092367   \n",
       "3                   0.001442                               0.096674   \n",
       "4                   0.002118                               0.110895   \n",
       "\n",
       "   Intensity_UpperQuartileIntensity_PI  Number_Object_Number  \n",
       "0                             0.037224                     1  \n",
       "1                             0.037316                     2  \n",
       "2                             0.032090                     3  \n",
       "3                             0.034585                     4  \n",
       "4                             0.035672                     5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfccc4-eb07-4750-a91d-9db96e05aea0",
   "metadata": {},
   "source": [
    "### 2. Problem **write_data**\n",
    "\n",
    "Write a function called **write_data**.\n",
    "\n",
    "This function will accept two parameters: a DataFrame called **df** and a **filename** (with extension).\n",
    "\n",
    "The function will determine the appropriate file type based on the extension of **filename** and write the contents of the DataFrame to that file.  \n",
    "\n",
    "For the purposes of this function, you can assume that your data frame will not have index names although this is irrelevent for .json files (index = False) and that if you write to a text file that you will use a \"|\" as a separator.\n",
    "\n",
    "This function should return True when finished. There are some circumstances where a write function might return False if it failed to write the file correctly, but here there is nothing computed to return so returning True just keeps us consistent with having functions reutrn values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2f14df-7ebf-44dc-aa9e-26fc6685170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 2 Solution Here\n",
    "def write_data(df, filename):\n",
    "    ext = os.path.splitext(filename)[1]  \n",
    "    if ext == '.xlsx':  \n",
    "        df.to_excel(filename, index=False)  \n",
    "    elif ext == '.json': \n",
    "        df.to_json(filename, orient='records')  \n",
    "    elif ext == '.csv': \n",
    "        df.to_csv(filename, index=False, sep='|')  \n",
    "    elif ext == '.txt':  \n",
    "        df.to_csv(filename, index=False, sep='|')  \n",
    "    else: \n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")  \n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0113b173-0043-47f4-9d7c-811ae1cbbbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4989ef3e-a5e4-4d12-b131-a188bba81a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Problem 2 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "49a92204-36ba-489a-b04c-a9c11657c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Team</th>\n",
       "      <th>Country</th>\n",
       "      <th>NameF</th>\n",
       "      <th>NameL</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HeightFt</th>\n",
       "      <th>HtIn</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Meghan</td>\n",
       "      <td>Agosta</td>\n",
       "      <td>148</td>\n",
       "      <td>5'7</td>\n",
       "      <td>540086400000</td>\n",
       "      <td>Ruthven</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>35</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>148</td>\n",
       "      <td>5'9</td>\n",
       "      <td>622598400000</td>\n",
       "      <td>Sudbury</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>32</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Stacey</td>\n",
       "      <td>156</td>\n",
       "      <td>5'10</td>\n",
       "      <td>768096000000</td>\n",
       "      <td>Kleinburg</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>28</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>172</td>\n",
       "      <td>5'10</td>\n",
       "      <td>613872000000</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>33</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jillian</td>\n",
       "      <td>Saulnier</td>\n",
       "      <td>144</td>\n",
       "      <td>5'5</td>\n",
       "      <td>699926400000</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>N.S.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>30</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Team Country     NameF      NameL  Weight Height           DOB  \\\n",
       "0   1  Women  Canada    Meghan     Agosta     148    5'7  540086400000   \n",
       "1   2  Women  Canada   Rebecca   Johnston     148    5'9  622598400000   \n",
       "2   3  Women  Canada     Laura     Stacey     156   5'10  768096000000   \n",
       "3   4  Women  Canada  Jennifer  Wakefield     172   5'10  613872000000   \n",
       "4   5  Women  Canada   Jillian   Saulnier     144    5'5  699926400000   \n",
       "\n",
       "    Hometown  Prov      Pos  Age  HeightFt  HtIn  BMI  \n",
       "0    Ruthven  Ont.  Forward   35  5.583333    67   23  \n",
       "1    Sudbury  Ont.  Forward   32  5.750000    69   22  \n",
       "2  Kleinburg  Ont.  Forward   28  5.833333    70   22  \n",
       "3  Pickering  Ont.  Forward   33  5.833333    70   25  \n",
       "4    Halifax  N.S.  Forward   30  5.416667    65   24  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1b7a8c45-66ba-4a4f-b397-0e2f4246751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(df, \"hockey_player.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b6b5892-1815-476a-bae5-bcced3e2b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = read_data(\"hockey_player.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "72681a2c-7366-49e0-b985-eab2701d6889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Team</th>\n",
       "      <th>Country</th>\n",
       "      <th>NameF</th>\n",
       "      <th>NameL</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HeightFt</th>\n",
       "      <th>HtIn</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Meghan</td>\n",
       "      <td>Agosta</td>\n",
       "      <td>148</td>\n",
       "      <td>5'7</td>\n",
       "      <td>1987-02-12</td>\n",
       "      <td>Ruthven</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>35</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>148</td>\n",
       "      <td>5'9</td>\n",
       "      <td>1989-09-24</td>\n",
       "      <td>Sudbury</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>32</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Stacey</td>\n",
       "      <td>156</td>\n",
       "      <td>5'10</td>\n",
       "      <td>1994-05-05</td>\n",
       "      <td>Kleinburg</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>28</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>172</td>\n",
       "      <td>5'10</td>\n",
       "      <td>1989-06-15</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>33</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jillian</td>\n",
       "      <td>Saulnier</td>\n",
       "      <td>144</td>\n",
       "      <td>5'5</td>\n",
       "      <td>1992-03-07</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>N.S.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>30</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Team Country     NameF      NameL  Weight Height         DOB  \\\n",
       "0   1  Women  Canada    Meghan     Agosta     148    5'7  1987-02-12   \n",
       "1   2  Women  Canada   Rebecca   Johnston     148    5'9  1989-09-24   \n",
       "2   3  Women  Canada     Laura     Stacey     156   5'10  1994-05-05   \n",
       "3   4  Women  Canada  Jennifer  Wakefield     172   5'10  1989-06-15   \n",
       "4   5  Women  Canada   Jillian   Saulnier     144    5'5  1992-03-07   \n",
       "\n",
       "    Hometown  Prov      Pos  Age  HeightFt  HtIn  BMI  \n",
       "0    Ruthven  Ont.  Forward   35  5.583333    67   23  \n",
       "1    Sudbury  Ont.  Forward   32  5.750000    69   22  \n",
       "2  Kleinburg  Ont.  Forward   28  5.833333    70   22  \n",
       "3  Pickering  Ont.  Forward   33  5.833333    70   25  \n",
       "4    Halifax  N.S.  Forward   30  5.416667    65   24  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bdb383-cb97-4d8a-8691-6421600cab2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Problem **copy_data**\n",
    "\n",
    "Write a function called **copy_data** that takes two filenames called **f1** and **f2** as parameters and copies the data from **f1** into **f2**.\n",
    "\n",
    "For the purposes of this problem, the function should read the contents of **f1** into a DataFrame and then write the contents of the DataFrame into **f2**.\n",
    "\n",
    "You should utilize your read_data and write_data from above to make this function super easy.\n",
    "\n",
    "This function should return True when it is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0241ec1-416b-499d-b38d-dd2c43bead4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Solution Problem 3 Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aca3b3d-f83c-4306-899e-18fe5fd89269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os  \n",
    "import pandas as pd  \n",
    "\n",
    "def read_data(filename):\n",
    "    \n",
    "\n",
    "    if filename.endswith('.xlsx'):  \n",
    "        return pd.read_excel(filename)  \n",
    "    elif filename.endswith('.json'):  \n",
    "        return pd.read_json(filename) \n",
    "    elif filename.endswith('.csv'): \n",
    "        return pd.read_csv(filename, sep='|')  \n",
    "    elif filename.endswith('.txt'):  \n",
    "        return pd.read_csv(filename, sep='|', header=None)  \n",
    "    else:  \n",
    "        raise ValueError('Unsupported file format')  \n",
    "\n",
    "def write_data(df, filename):\n",
    "   \n",
    "\n",
    "    if filename.endswith('.xlsx'):  \n",
    "        df.to_excel(filename, index=False)  \n",
    "    elif filename.endswith('.json'):  #condition set for json\n",
    "        df.to_json(filename, orient='records')  \n",
    "    elif filename.endswith('.csv'):  #csv\n",
    "        df.to_csv(filename, sep='|', index=False)  \n",
    "    elif filename.endswith('.txt'):  #txt\n",
    "        with open(filename, 'w') as f: #write\n",
    "            f.write(df.to_string(index=False, header=False))  \n",
    "    else:  \n",
    "        raise ValueError('Unsupported file format')  #\n",
    "\n",
    "    return True  # \n",
    "\n",
    "def copy_data(f1, f2):\n",
    "    \n",
    "    df = read_data(f1)  \n",
    "    write_data(df, f2)  \n",
    "\n",
    "    return True  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71108fae-625b-4a9e-9f91-d80c7e40fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Solution Problem 3 Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "411daff8-4b89-4b3c-bf84-7452ff4c9bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data(\"hockey_player.json\", \"hp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc72f75a-9a2b-4c89-86fe-f0c89d2ae5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Team</th>\n",
       "      <th>Country</th>\n",
       "      <th>NameF</th>\n",
       "      <th>NameL</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HeightFt</th>\n",
       "      <th>HtIn</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Meghan</td>\n",
       "      <td>Agosta</td>\n",
       "      <td>148</td>\n",
       "      <td>5'7</td>\n",
       "      <td>540086400000</td>\n",
       "      <td>Ruthven</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>35</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>148</td>\n",
       "      <td>5'9</td>\n",
       "      <td>622598400000</td>\n",
       "      <td>Sudbury</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>32</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Stacey</td>\n",
       "      <td>156</td>\n",
       "      <td>5'10</td>\n",
       "      <td>768096000000</td>\n",
       "      <td>Kleinburg</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>28</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>172</td>\n",
       "      <td>5'10</td>\n",
       "      <td>613872000000</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>Ont.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>33</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Women</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jillian</td>\n",
       "      <td>Saulnier</td>\n",
       "      <td>144</td>\n",
       "      <td>5'5</td>\n",
       "      <td>699926400000</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>N.S.</td>\n",
       "      <td>Forward</td>\n",
       "      <td>30</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Team Country     NameF      NameL  Weight Height           DOB  \\\n",
       "0   1  Women  Canada    Meghan     Agosta     148    5'7  540086400000   \n",
       "1   2  Women  Canada   Rebecca   Johnston     148    5'9  622598400000   \n",
       "2   3  Women  Canada     Laura     Stacey     156   5'10  768096000000   \n",
       "3   4  Women  Canada  Jennifer  Wakefield     172   5'10  613872000000   \n",
       "4   5  Women  Canada   Jillian   Saulnier     144    5'5  699926400000   \n",
       "\n",
       "    Hometown  Prov      Pos  Age  HeightFt  HtIn  BMI  \n",
       "0    Ruthven  Ont.  Forward   35  5.583333    67   23  \n",
       "1    Sudbury  Ont.  Forward   32  5.750000    69   22  \n",
       "2  Kleinburg  Ont.  Forward   28  5.833333    70   22  \n",
       "3  Pickering  Ont.  Forward   33  5.833333    70   25  \n",
       "4    Halifax  N.S.  Forward   30  5.416667    65   24  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = read_data(\"hp.txt\")\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03d4f1-92db-43da-86d1-fb61591a3b25",
   "metadata": {},
   "source": [
    "### 4. Problem **write_data2**  (OPTIONAL - No points counted for this) \n",
    "\n",
    "Write a function called **write_data2** that takes a DataFrame, a Filename (with extension), a list containing column names, and a list containing row numbers.\n",
    "\n",
    "The function should write just the subset of that DataFrame containing only those columns and rows specified to the filename.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcdbe0-da06-45af-b14a-22b9584e9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 4 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7f764e-2ca6-4431-a40f-3439b6c35b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_data2(df, filename, columns, rows):\n",
    "    \n",
    "    df_subset = df.loc[rows, columns]  \n",
    "    \n",
    "    ext = os.path.splitext(filename)[1]  \n",
    "    if ext == '.xlsx':  \n",
    "        df_subset.to_excel(filename, index=False)  \n",
    "    elif ext == '.json': \n",
    "        df_subset.to_json(filename, orient='records')  \n",
    "    elif ext == '.csv':  \n",
    "        df_subset.to_csv(filename, sep='|', index=False)  \n",
    "    elif ext == '.txt': \n",
    "        with open(filename, 'w') as f: \n",
    "            f.write(df_subset.to_csv(sep='|', index=False))  \n",
    "    else:  \n",
    "        raise ValueError('Unsupported file format')  \n",
    "    \n",
    "    return True  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Problem 4 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc174663",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data2(df, \"foo.xlsx\",[\"ID\",\"NameF\",\"Country\"],[0,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data(\"foo.xlsx\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035375de-774a-4d3c-9e8b-92ee18002a76",
   "metadata": {},
   "source": [
    "### 5. Problem **scrape_table**\n",
    "\n",
    "Write a function called **scrape_table**.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "    url: A URL to a webpage (guaranteed to have at least one table)\n",
    "   \n",
    "    n:   A zero based number designating the table to return\n",
    "\n",
    "**Return:**\n",
    "A dataframe with the Nth Table.\n",
    "\n",
    "**Error_Checking:**\n",
    "\n",
    "If N is larger than the number of tables on the page then the function should return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce799c-2cbb-43cb-aeba-fabac00d5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 5 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671438d0-4f7f-4da5-aac2-a48af77faea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup #import lib from urls\n",
    "\n",
    "def scrape_table(url, n):\n",
    "   \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    if n >= len(tables):\n",
    "        return None\n",
    "\n",
    "    table = tables[n]\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee1ad7-7e9e-4c9a-a037-8e7bf3afa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Problem 5 Solution Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cdbe9-03a8-470e-a0af-c6224b595619",
   "metadata": {},
   "source": [
    "### 6. Problem **scrape_tables_to_csv**\n",
    "\n",
    "Write a functions called **scrape_tables_to_csv**\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "    url: A url to a page with a least one table\n",
    "    base_file_name: A filename with no extension\n",
    "    maximum = 100000: Optional parameter specifying max number of tables to scrape\n",
    "\n",
    "The function should scrape all of the tables from the url and convert them into dataframes.  The function should write either all of the dataframes or the maximum number of dataframes (whichever is smaller) into separate csv files.  \n",
    "\n",
    "The csv files should follow the following naming convention: basefilename_table_number.  Where number is an integer starting at 0 and counting upwards with each additional table. \n",
    "\n",
    "This function will potentially create many files on your machine (although they will be small files). You will want to manage these files and delete them manually after most tests so you can be sure your code is continuing to work correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641cf19f-7982-43e0-b56e-28ef8ce033bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 6 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a34377-f28e-4b3e-b4b9-2205f1ed92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def scrape_tables_to_csv(url, base_file_name, maximum=100000):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "    if maximum < len(tables):\n",
    "        tables = tables[:maximum]\n",
    "    for i, table in enumerate(tables):\n",
    "        cwd = os.getcwd()  \n",
    "        filepath = os.path.join(cwd, f\"{base_file_name}_table_{i}.csv\")\n",
    "\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "u = \"https://en.wikipedia.org/wiki/Demographics_of_the_United_States/tables\"\n",
    "def read_data(filename):\n",
    "    if filename.endswith('.json'):\n",
    "        return pd.read_json(filename) \n",
    "    elif filename.endswith('.csv'):\n",
    "        return pd.read_csv(filename, sep='|')  \n",
    "    elif filename.endswith('.txt'):\n",
    "        return pd.read_csv(filename, sep='|', header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17af79ab-e516-4f9f-a33d-66308f57efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country / Area UN continentalregion[4] UN statisticalsubregion[4]  \\\n",
      "0             India                    Asia              Southern Asia   \n",
      "1          China[a]                    Asia               Eastern Asia   \n",
      "2  United States[b]           North America           Northern America   \n",
      "3         Indonesia                    Asia          Southeastern Asia   \n",
      "4          Pakistan                    Asia              Southern Asia   \n",
      "\n",
      "   Population(1 July 2022)  Population(1 July 2023)  Change  \n",
      "0               1417173173               1428627663  +0.81%  \n",
      "1               1425887337               1425671352  −0.02%  \n",
      "2                338289857                339996564  +0.50%  \n",
      "3                275501339                277534123  +0.74%  \n",
      "4                235824863                240485658  +1.98%  \n"
     ]
    }
   ],
   "source": [
    "#End Problem 6 Solution Here\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)'\n",
    "df = scrape_table(url, 0)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29341a5f-6249-45c1-a72e-af1dc093c644",
   "metadata": {},
   "source": [
    "### 7. Problem **tester**\n",
    "\n",
    "Write a function called **tester**\n",
    "\n",
    "Tester will accept 3 parameters: a filename (with an extension), a row_number, and a column_number.\n",
    "\n",
    "Tester will read in that file and return the value in the dataframe in column **column_number** and row **row_number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935eaa3e-84c5-4017-87a6-cab45a46dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Problem 7 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797cd7e-1067-43bb-9e40-9746fb149971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed39294-0cac-4051-8932-84d76aae3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Problem 7 Solution Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af3705bc-14e9-4e9b-9deb-2b4f52dfa41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Halifax'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester(\"hockeyplayers.xlsx\", 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "369e389a-3908-45fd-97a5-0923522195b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life expectancy'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester(\"dem_table2.csv\", 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568df190",
   "metadata": {},
   "source": [
    "# MINI PROJECT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39eabe78",
   "metadata": {},
   "source": [
    "Car Parking Slot Availability Checker\n",
    "\n",
    "Description: Develop a simple program to manage Car parking slot availability near Roux-Institute@Downtown Portland.\n",
    "The program should allow users to check whether a parking slot is available or not.\n",
    "\n",
    "Requirements:\n",
    "Assume total avialble parking slots as 10(ten). Write following functions:\n",
    "1.\tcheck_availability(available, slot_number): Check if the given slot_number is available. Return True if the slot is available, otherwise return False.\n",
    "2.\tpark_car(available, slot_number): If the given slot_number is available, mark it as occupied and return a message indicating successful parking. If the slot is not available, return a message indicating unavailability.\n",
    "OPTIONAL: If are familair with OOP and want to implement CLASS Method, you can create a ParkingArea class with a specified number of total parking slots.\n",
    "Implement a loop that repeatedly prompts the user for a slot number and performs the following:\n",
    "If the slot is available, ask the user if they want to park a car there. If yes, call the park_car method and print the corresponding message. If no, display a message indicating the slot is available. If the slot is not available, print a message indicating that the slot is occupied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e450f87",
   "metadata": {},
   "source": [
    "# Example Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad5517",
   "metadata": {},
   "source": [
    "Welcome to the Car Parking Area!\n",
    "Total parking slots: 10\n",
    "Enter a slot number to check availability (1-10) or enter -1 to exit: 5\n",
    "Slot 5 is available. Do you want to park a car there? (yes/no): yes\n",
    "Car parked in slot 5.\n",
    "Enter a slot number to check availability (1-10) or enter -1 to exit: 5 Slot 5 is occupied.\n",
    "Enter a slot number to check availability (1-10) or enter -1 to exit: 8 Slot 8 is available. Do you want to park a car there? (yes/no): no Slot 8 is available.\n",
    "Enter a slot number to check availability (1-10) or enter -1 to exit: -1 Exiting the program. Thank you! Submission:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "681c1843",
   "metadata": {},
   "source": [
    "INSTRUCTIONS TO SUBMIT ASSIGNMENT:\n",
    "•\tComment your code throughout and provide proper description what you are intend to do\n",
    "•\tFeel free to customize the assignment and the example output according to your preferences and requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_availability(available, slot_number):\n",
    "    \n",
    "    return slot_number in available\n",
    "\n",
    "def park_car(available, slot_number):\n",
    "    \n",
    "    if check_availability(available, slot_number):\n",
    "        available.remove(slot_number)\n",
    "        return f\"Parked car in slot {slot_number}\"\n",
    "    else:\n",
    "        return f\"Sorry, slot {slot_number} is already occupied.\"\n",
    "\n",
    "available = list(range(1, 11))\n",
    "while True:\n",
    "   \n",
    "    slot_number = input(\"Enter a slot number (or 'quit' to exit): \")\n",
    "\n",
    "    if slot_number == 'quit':\n",
    "        break\n",
    "    slot_number = int(slot_number)\n",
    "    \n",
    "    if check_availability(available, slot_number):\n",
    "        \n",
    "        park = input(f\"Slot {slot_number} is available. Do you want to park a car there? (y/n) \")\n",
    "        \n",
    "        if park == 'y':\n",
    "            print(park_car(available, slot_number))\n",
    "        else:\n",
    "            print(f\"Slot {slot_number} is available.\")\n",
    "    else:\n",
    "        print(f\"Sorry, slot {slot_number} is already occupied.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
